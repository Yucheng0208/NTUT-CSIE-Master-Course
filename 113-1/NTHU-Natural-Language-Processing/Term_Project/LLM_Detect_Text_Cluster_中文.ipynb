{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Detect: Text Cluster [中文]\n",
    "[Link](https://www.kaggle.com/code/finlay/llm-detect-text-cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "�t�Χ䤣����w�����|�C\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 数据路径\n",
    "#DATA_PATH = './input'\n",
    "#DATA_PATH = '/kaggle/input/llm-detect-ai-generated-text'\n",
    "DATA_PATH = 'D:/NTUT-CSIE-Master-Course/113-1/NTHU-Natural-Language-Processing/Term_Project/input_data'\n",
    "\n",
    "# 读取训练集文章数据\n",
    "train_essays = pd.read_csv(f'{DATA_PATH}/train_essays.csv')\n",
    "\n",
    "# 读取训练集作文题目数据\n",
    "train_prompts = pd.read_csv(f'{DATA_PATH}/train_prompts.csv')\n",
    "\n",
    "# 读取测试集文章数据\n",
    "test_essays = pd.read_csv(f'{DATA_PATH}/test_essays.csv')\n",
    "\n",
    "# 读取样本提交文件\n",
    "sample_submit = pd.read_csv(f'{DATA_PATH}/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\ryan\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from kaggle) (2024.8.30)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ryan\\appdata\\roaming\\python\\python311\\site-packages (from kaggle) (2.9.0.post0)\n",
      "Requirement already satisfied: requests in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from kaggle) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from kaggle) (4.66.5)\n",
      "Requirement already satisfied: python-slugify in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from kaggle) (2.2.3)\n",
      "Requirement already satisfied: bleach in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from kaggle) (4.1.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\ryan\\appdata\\roaming\\python\\python311\\site-packages (from bleach->kaggle) (24.1)\n",
      "Requirement already satisfied: webencodings in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from requests->kaggle) (3.7)\n",
      "Requirement already satisfied: colorama in c:\\users\\ryan\\anaconda3\\envs\\nlp\\lib\\site-packages (from tqdm->kaggle) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install kaggle\n",
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.3.4)\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/thedrcat/daigt-v2-train-dataset?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2.00M/28.5M [00:00<00:11, 2.41MB/s]"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "path = kagglehub.dataset_download(\"thedrcat/daigt-v2-train-dataset\")\n",
    "# Move the downloaded dataset to the DATA_PATH\n",
    "shutil.move(path, DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载外数据集\n",
    "#train_v2_drcat_02_path = '/kaggle/input/daigt-v2-train-dataset/train_v2_drcat_02.csv'\n",
    "train_v2_drcat_02_path = 'D:/NTUT-CSIE-Master-Course/113-1/NTHU-Natural-Language-Processing/Term_Project/input_data/train_v2_drcat_02.csv'\n",
    "train = pd.read_csv(train_v2_drcat_02_path, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 合并外部数据集\n",
    "# train = pd.concat([\n",
    "#     train_essays.rename({'generated': 'label'}, axis=1)[['text', 'label']],\n",
    "#     train[['text', 'label']]\n",
    "# ],axis=0)\n",
    "\n",
    "# 按照文本内容进行去重\n",
    "train = train.drop_duplicates(subset=['text'])\n",
    "train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U sentence-transformers\n",
    "!pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "# 加载与训练模型\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行文本编码\n",
    "embeddings = model.encode(train['text'], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_pca = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for c in train['label'].unique():\n",
    "    plt.scatter(embeddings_pca[train['label']==c, 0],\n",
    "                embeddings_pca[train['label']==c, 1])\n",
    "plt.legend(train['label'].unique(), title='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train['prompt_name'].unique():\n",
    "    plt.scatter(embeddings_pca[train['prompt_name']==c, 0],\n",
    "                embeddings_pca[train['prompt_name']==c, 1])\n",
    "plt.legend(train['prompt_name'].unique(), title='prompt_name', bbox_to_anchor=(1, 1.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "X = np.array([[0, 0, 0], [0, 1, 1], [1, 0, 1], [1, 1, 1]])\n",
    "X_embedded = TSNE(n_components=2, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(X)\n",
    "X_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_index = np.random.choice(range(44868), 5000)\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "embeddings_tsne = tsne.fit_transform(embeddings[data_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train['label'].iloc[data_index].unique():\n",
    "    plt.scatter(embeddings_tsne[train['label'].iloc[data_index]==c, 0],\n",
    "                embeddings_tsne[train['label'].iloc[data_index]==c, 1])\n",
    "\n",
    "plt.legend(train['label'].iloc[data_index].unique(), title='label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in train['prompt_name'].iloc[data_index].unique():\n",
    "    plt.scatter(embeddings_tsne[train['prompt_name'].iloc[data_index]==c, 0],\n",
    "                embeddings_tsne[train['prompt_name'].iloc[data_index]==c, 1])\n",
    "\n",
    "plt.legend(train['prompt_name'].unique(), title='prompt_name', bbox_to_anchor=(1, 1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
